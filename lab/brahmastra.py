# -*- coding: utf-8 -*-
"""Brahmastra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ODpUG37XVucL2R6vsh6hNuO9lzSmqGzX
"""

import pandas as pd
import numpy as np
import seaborn as sns
import math
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from google.colab import files
seed=29

data = pd.read_csv('/content/cardio_train 2.csv', sep=';')

data

data.isna().sum()

df_final = data[:2000]

df_final

df_final.describe()

df_final.dtypes

"""**Outliers**"""

#Identification of Outliers
from matplotlib import pyplot as plt
import seaborn as sns
fig, axes = plt.subplots(1, 5, figsize=(16, 5))
sns.boxplot(data=df_final, y='age', ax=axes[0])
sns.boxplot(data=df_final, y='height', ax=axes[1])
sns.boxplot(data=df_final, y='weight', ax=axes[2])
sns.boxplot(data=df_final, y='ap_hi', ax=axes[3])
sns.boxplot(data=df_final, y='ap_lo', ax=axes[4])
plt.tight_layout()
plt.savefig("Outliers.png")
files.download("Outliers.png")

"""**Distribution of attributes**"""

# Distribution graphs (histogram/bar graph) of column data
def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):
    nunique = df.nunique()
    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = df.shape
    columnNames = list(df)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.savefig("distribution1.png")
    files.download("distribution1.png")
    plt.show()

plotPerColumnDistribution(df_final, 10, 3)

corrMatrix = df_final.corr()
plt.figure(figsize = (10,10),dpi=80, facecolor='w', edgecolor='k')
sns.heatmap(corrMatrix, annot=True)

plt.savefig("Corr_matrix.png")
files.download("Corr_matrix.png")
plt.show()

"""**Removing Outliers**"""

def remove_outliers(df,fieldname):
  Q1 = df[fieldname].quantile(0.25)
  Q3 = df[fieldname].quantile(0.75)
  IQR = Q3 - Q1
  whisker_width = 1.5
  lower_whisker = Q1 -(whisker_width*IQR)
  upper_whisker = Q3 + (whisker_width*IQR)
  df[fieldname]=np.where(df[fieldname]>upper_whisker,upper_whisker,np.where(df[fieldname]<lower_whisker,lower_whisker,df[fieldname]))

remove_outliers(df_final,'height')
remove_outliers(df_final,'weight')
remove_outliers(df_final,'ap_hi')
remove_outliers(df_final,'ap_lo')

fig, axes = plt.subplots(1, 5, figsize=(16, 5))
sns.boxplot(data=df_final, y='age', ax=axes[0])
sns.boxplot(data=df_final, y='height', ax=axes[1])
sns.boxplot(data=df_final, y='weight', ax=axes[2])
sns.boxplot(data=df_final, y='ap_hi', ax=axes[3])
sns.boxplot(data=df_final, y='ap_lo', ax=axes[4])
plt.tight_layout()

"""**ID**
No use of this attribute so removing this

"""

df_final.drop('id',axis =1,inplace=True)

"""**AGE**


"""

df_final['age'].describe()

scale= StandardScaler()
df_final['age'] = scale.fit_transform(df_final['age'].values.reshape(-1,1)).reshape(2000,)

"""**Height**"""

df_final['height'].describe()

df_final['height'] = scale.fit_transform(df_final['height'].values.reshape(-1,1)).reshape(2000,)

"""**Weight**"""

df_final['weight'].describe()

df_final['weight'] = scale.fit_transform(df_final['weight'].values.reshape(-1,1)).reshape(2000,)

"""**Ap_hi**"""

df_final['ap_hi'].describe()

df_final['ap_hi'] = scale.fit_transform(df_final['ap_hi'].values.reshape(-1,1)).reshape(2000,)

"""**Ap_lo**"""

df_final['ap_lo'].describe()

df_final['ap_lo'] = scale.fit_transform(df_final['ap_lo'].values.reshape(-1,1)).reshape(2000,)

df_final

df_final.describe()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import random
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
seed=29

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

X = df_final.iloc[:,:-1].values
y = df_final.iloc[:,-1].values

"""**Decision Tree (Hold Out spliting)**"""

# Split dataset into training set and test set
print("SPLIT TYPE: holdout method")
l = [0.20,0.25,0.33]
for i in l:
  print("\tSPLIT Ratio:",i)
  X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=100,test_size=i)
  # Create Decision Tree classifer object
  clf = DecisionTreeClassifier()

  # Train Decision Tree Classifer
  clf = clf.fit(X_train,y_train)

  #Predict the response for test dataset
  y_pred = clf.predict(X_test)
  print("\tAccuracy:",metrics.accuracy_score(y_test, y_pred))
  print("\tPrecision:" ,precision_score(y_test, y_pred))
  print('\tRecall:', recall_score(y_test, y_pred))
  print('\tF1 Score: ', f1_score(y_test, y_pred))
  # confusion matrix
  matrix = confusion_matrix(y_test,y_pred, labels=[1,0])
  print('Confusion matrix : \n',matrix)

  plt.figure(figsize=(20,4))

  sns.set(font_scale=1)
  labels = [0,1]
        # representing A in heatmap format
  cmap1=sns.light_palette("purple")

  plt.subplot(1, 3, 1)
  sns.heatmap(matrix, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
  plt.xlabel('Predicted Class')
  plt.ylabel('Original Class')
  plt.title("Confusion matrix")
  plt.show()

"""**Navies Bayes (Hold out spliting)**"""

# Split dataset into training set and test set
print("SPLIT TYPE: holdout method")
l = [0.20,0.25,0.33]
for i in l:
  print("\tSPLIT Ratio:",i)
  X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=100,test_size=i)
  # Create Decision Tree classifer object
  classifier = GaussianNB()

  # Train Decision Tree Classifer
  classifier.fit(X_train, y_train)

  #Predict the response for test dataset
  y_pred = classifier.predict(X_test)
  print("\tAccuracy:",metrics.accuracy_score(y_test, y_pred))
  print("\tPrecision:" ,precision_score(y_test, y_pred))
  print('\tRecall:', recall_score(y_test, y_pred))
  print('\tF1 Score: ', f1_score(y_test, y_pred))
  # confusion matrix
  matrix = confusion_matrix(y_test,y_pred, labels=[1,0])
  print('Confusion matrix : \n',matrix)

  plt.figure(figsize=(20,4))

  sns.set(font_scale=1)
  labels = [0,1]
        # representing A in heatmap format
  cmap1=sns.light_palette("purple")

  plt.subplot(1, 3, 1)
  sns.heatmap(matrix, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
  plt.xlabel('Predicted Class')
  plt.ylabel('Original Class')
  plt.title("Confusion matrix")
  plt.show()

"""**KNN (Hold out Spliting)**"""

# Split dataset into training set and test set
print("SPLIT TYPE: holdout method")
l = [0.20,0.25,0.33]
for i in l:
  print("\tSPLIT Ratio:",i)
  X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=100,test_size=i)
  # Create Decision Tree classifer object
  neigh = KNeighborsClassifier(n_neighbors=10)

  # Train Decision Tree Classifer
  neigh.fit(X_train, y_train)

  #Predict the response for test dataset
  y_pred = classifier.predict(X_test)
  print("\tAccuracy:",metrics.accuracy_score(y_test, y_pred))
  print("\tPrecision:" ,precision_score(y_test, y_pred))
  print('\tRecall:', recall_score(y_test, y_pred))
  print('\tF1 Score: ', f1_score(y_test, y_pred))

  # confusion matrix
  matrix = confusion_matrix(y_test,y_pred, labels=[1,0])
  print('Confusion matrix : \n',matrix)

  plt.figure(figsize=(20,4))

  sns.set(font_scale=1)
  labels = [0,1]
        # representing A in heatmap format
  cmap1=sns.light_palette("purple")

  plt.subplot(1, 3, 1)
  sns.heatmap(matrix, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
  plt.xlabel('Predicted Class')
  plt.ylabel('Original Class')
  plt.title("Confusion matrix")
  plt.show()

"""**KNN (Random Subsampling spliting)**

"""

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = KNeighborsClassifier(n_neighbors=10)
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("green")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_randomSubsampling(_X,_y, test_size,n):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    for _ in range(n):
        random_state = random.randint(0,1000)
        X_traint,X_testt,y_traint,y_testt = train_test_split(_X,_y,random_state=random_state,test_size=test_size)
        X_train.append(X_traint)
        X_test.append(X_testt)
        y_train.append(y_traint)
        y_test.append(y_testt)
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Random Subsampling method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_randomSubsampling(X,y,i,round(1/i))

"""**Desicion Tree (Random Subsampling spliting)**"""

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = DecisionTreeClassifier()
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("green")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_randomSubsampling(_X,_y, test_size,n):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    for _ in range(n):
        random_state = random.randint(0,1000)
        X_traint,X_testt,y_traint,y_testt = train_test_split(_X,_y,random_state=random_state,test_size=test_size)
        X_train.append(X_traint)
        X_test.append(X_testt)
        y_train.append(y_traint)
        y_test.append(y_testt)
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Random Subsampling method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_randomSubsampling(X,y,i,round(1/i))

"""**Navies Bayes (Random Subsampling spliting)**"""

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = GaussianNB()
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("green")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_randomSubsampling(_X,_y, test_size,n):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    for _ in range(n):
        random_state = random.randint(0,1000)
        X_traint,X_testt,y_traint,y_testt = train_test_split(_X,_y,random_state=random_state,test_size=test_size)
        X_train.append(X_traint)
        X_test.append(X_testt)
        y_train.append(y_traint)
        y_test.append(y_testt)
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Random Subsampling method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_randomSubsampling(X,y,i,round(1/i))

"""**Desicion Tree (Cross Validation spliting)**"""

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = DecisionTreeClassifier()
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("Blue")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_crossValidation(_X,_y,k):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    kf = StratifiedKFold(n_splits = k, shuffle = True)
    for train_index, test_index in kf.split(X,y):
        X_train.append(X[train_index])
        X_test.append(X[test_index])
        y_train.append(y[train_index])
        y_test.append(y[test_index])
    n=k    
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Cross Validation method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_crossValidation(X,y,round(1/i))

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = KNeighborsClassifier(n_neighbors=10)
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("Blue")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_crossValidation(_X,_y,k):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    kf = StratifiedKFold(n_splits = k, shuffle = True)
    for train_index, test_index in kf.split(X,y):
        X_train.append(X[train_index])
        X_test.append(X[test_index])
        y_train.append(y[train_index])
        y_test.append(y[test_index])
    n=k    
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Cross Validation method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_crossValidation(X,y,round(1/i))

recall_l = list()
f1_score_l = list()
accuracy_l = list()
precision_l = list()

def model_eval(X_train,X_test,y_train, y_test,n):
    y_pred = list()
    con_matrix = [[0,0],[0,0]]
    accuracy,f1score,precision,recall = list(),list(),list(),list()
    for i in range(n):
        model = GaussianNB()
        model.fit(X_train[i],y_train[i])
        y_pred.append(model.predict(X_test[i]))
        accuracy.append(accuracy_score(y_test[i],y_pred[i]))
        f1score.append(f1_score(y_test[i],y_pred[i]))
        precision.append(precision_score(y_test[i],y_pred[i]))
        recall.append(recall_score(y_test[i],y_pred[i]))
        cm = confusion_matrix(y_test[i],y_pred[i])
        con_matrix = [[con_matrix[k][j] + cm[k][j]  for j in range(2)] for k in range(2)]
    accuracy = sum(accuracy)/n
    f1score = sum(f1score)/n
    precision = sum(precision)/n
    recall = sum(recall)/n
    con_matrix = [[round(con_matrix[k][j]/n)  for j in range(2)] for k in range(2)]
    print(f'\taccuracy:{accuracy}\n\tf1_score:{f1score}\n\tprecision{precision}:\n\trecall:{recall}')
    metrics_plot(con_matrix)

def metrics_plot(C):
    plt.figure(figsize=(20,4))

    sns.set(font_scale=1)
    labels = [0,1]
    # representing A in heatmap format
    cmap1=sns.light_palette("Blue")

    plt.subplot(1, 3, 1)
    sns.heatmap(C, annot=True, cmap=cmap1, fmt="d", xticklabels=labels, yticklabels=labels,annot_kws={"size":14})
    plt.xlabel('Predicted Class')
    plt.ylabel('Original Class')
    plt.title("Confusion matrix")

    plt.show()

def train_test_split_crossValidation(_X,_y,k):
    X_train,X_test,y_train,y_test = list(),list(),list(),list()
    kf = StratifiedKFold(n_splits = k, shuffle = True)
    for train_index, test_index in kf.split(X,y):
        X_train.append(X[train_index])
        X_test.append(X[test_index])
        y_train.append(y[train_index])
        y_test.append(y[test_index])
    n=k    
    model_eval(X_train,X_test,y_train, y_test,n)

# Split dataset into training set and test set
print("SPLIT TYPE: Cross Validation method")
sample = [0.20,0.25,0.33]
for i in sample:
  print("\tSPLIT Ratio:",i)
  train_test_split_crossValidation(X,y,round(1/i))

