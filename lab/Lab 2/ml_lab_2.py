# -*- coding: utf-8 -*-
"""ML_lab_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ugVbwZ9NP5EyVtBDrxhgj0-XduJIIBiF

# Q2) Download any Dataset from ML UCI repository and apply all Preprocessing Tools for:
1)Handling Missing Data

2)Encoding Independent and Dependent Variables

3)Splitting the Dataset into the Training and Test Set

4)Feature Scaling
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('/content/car.data')
df

x= df.iloc[:,-1].values #dependent
x

y= df.iloc[:,:-1].values #indepent
y

"""## Checking Nan values"""

df.isna().sum()   #no null values

#df['Class'].fillna(value=df['Class'].mean(), inplace=True)

"""## Encoding categorical data"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0,1,4,5])], remainder = 'passthrough') #for independent

y = np.array(ct.fit_transform(y))
y

from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
x = l.fit_transform(x)
x

"""## Splitting data"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)

print(X_test)

print(X_train)

print(Y_test)

print(Y_train)

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler #feature scaling was not needed still done to show steps
sc = StandardScaler()

Y_train[:, -2:] = sc.fit_transform(Y_train[:, -2:])

Y_test[:, -2:] = sc.transform(Y_test[:, -2:])

print(Y_train)

print(Y_test)